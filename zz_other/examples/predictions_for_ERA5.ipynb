{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7d81b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is failing on boulmich_beast"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f57a10-13a1-4f66-a734-065fc16b17b2",
      "metadata": {},
      "source": [
        "# Predictions for ERA5\n",
        "\n",
        "In this example, we will download ERA5 data for 1 Jan 2023 at 0.25 degrees resolution and run Aurora on this data. The fine-tuned version of Aurora specifically only works with IFS HRES T0, so we use the non-fine-tuned version of Aurora in this example.\n",
        "\n",
        "Running this notebook requires additional Python packages. You can install these as follows:\n",
        "\n",
        "```\n",
        "pip install cdsapi matplotlib\n",
        "```\n",
        "\n",
        "## Downloading the Data\n",
        "\n",
        "To begin with, register an account with the [Climate Data Store](https://cds.climate.copernicus.eu/) and create `$HOME/.cdsapirc` with the following content:\n",
        "\n",
        "```\n",
        "url: https://cds.climate.copernicus.eu/api\n",
        "key: <API key>\n",
        "```\n",
        "\n",
        "You can find your API key on your account page.\n",
        "\n",
        "In order to be able to download ERA5 data, you need to accept the terms of use in the [dataset page](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=download).\n",
        "\n",
        "We now download the ERA5 data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0541bf19-024f-4c76-8666-9d559640156e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Static variables downloaded!\n",
            "Surface-level variables downloaded!\n",
            "Atmospheric variables downloaded!\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import cdsapi\n",
        "\n",
        "# Data will be downloaded here.\n",
        "download_path = Path(\"~/downloads/era5\")\n",
        "\n",
        "c = cdsapi.Client()\n",
        "\n",
        "download_path = download_path.expanduser()\n",
        "download_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download the static variables.\n",
        "if not (download_path / \"static.nc\").exists():\n",
        "    c.retrieve(\n",
        "        \"reanalysis-era5-single-levels\",\n",
        "        {\n",
        "            \"product_type\": \"reanalysis\",\n",
        "            \"variable\": [\n",
        "                \"geopotential\",\n",
        "                \"land_sea_mask\",\n",
        "                \"soil_type\",\n",
        "            ],\n",
        "            \"year\": \"2023\",\n",
        "            \"month\": \"01\",\n",
        "            \"day\": \"01\",\n",
        "            \"time\": \"00:00\",\n",
        "            \"format\": \"netcdf\",\n",
        "        },\n",
        "        str(download_path / \"static.nc\"),\n",
        "    )\n",
        "print(\"Static variables downloaded!\")\n",
        "\n",
        "# Download the surface-level variables.\n",
        "if not (download_path / \"2023-01-01-surface-level.nc\").exists():\n",
        "    c.retrieve(\n",
        "        \"reanalysis-era5-single-levels\",\n",
        "        {\n",
        "            \"product_type\": \"reanalysis\",\n",
        "            \"variable\": [\n",
        "                \"2m_temperature\",\n",
        "                \"10m_u_component_of_wind\",\n",
        "                \"10m_v_component_of_wind\",\n",
        "                \"mean_sea_level_pressure\",\n",
        "            ],\n",
        "            \"year\": \"2023\",\n",
        "            \"month\": \"01\",\n",
        "            \"day\": \"01\",\n",
        "            \"time\": [\"00:00\", \"06:00\", \"12:00\", \"18:00\"],\n",
        "            \"format\": \"netcdf\",\n",
        "        },\n",
        "        str(download_path / \"2023-01-01-surface-level.nc\"),\n",
        "    )\n",
        "print(\"Surface-level variables downloaded!\")\n",
        "\n",
        "# Download the atmospheric variables.\n",
        "if not (download_path / \"2023-01-01-atmospheric.nc\").exists():\n",
        "    c.retrieve(\n",
        "        \"reanalysis-era5-pressure-levels\",\n",
        "        {\n",
        "            \"product_type\": \"reanalysis\",\n",
        "            \"variable\": [\n",
        "                \"temperature\",\n",
        "                \"u_component_of_wind\",\n",
        "                \"v_component_of_wind\",\n",
        "                \"specific_humidity\",\n",
        "                \"geopotential\",\n",
        "            ],\n",
        "            \"pressure_level\": [\n",
        "                \"50\",\n",
        "                \"100\",\n",
        "                \"150\",\n",
        "                \"200\",\n",
        "                \"250\",\n",
        "                \"300\",\n",
        "                \"400\",\n",
        "                \"500\",\n",
        "                \"600\",\n",
        "                \"700\",\n",
        "                \"850\",\n",
        "                \"925\",\n",
        "                \"1000\",\n",
        "            ],\n",
        "            \"year\": \"2023\",\n",
        "            \"month\": \"01\",\n",
        "            \"day\": \"01\",\n",
        "            \"time\": [\"00:00\", \"06:00\", \"12:00\", \"18:00\"],\n",
        "            \"format\": \"netcdf\",\n",
        "        },\n",
        "        str(download_path / \"2023-01-01-atmospheric.nc\"),\n",
        "    )\n",
        "print(\"Atmospheric variables downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7d8aa4-a16b-481c-b7e5-66764d6e98f1",
      "metadata": {},
      "source": [
        "## Preparing a Batch\n",
        "\n",
        "We convert the downloaded data to an `aurora.Batch`, which is what the model requires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fba4fb22-475b-4156-94c8-e61c77a20539",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import xarray as xr\n",
        "\n",
        "from aurora import Batch, Metadata\n",
        "\n",
        "static_vars_ds = xr.open_dataset(download_path / \"static.nc\", engine=\"netcdf4\")\n",
        "surf_vars_ds = xr.open_dataset(download_path / \"2023-01-01-surface-level.nc\", engine=\"netcdf4\")\n",
        "atmos_vars_ds = xr.open_dataset(download_path / \"2023-01-01-atmospheric.nc\", engine=\"netcdf4\")\n",
        "\n",
        "batch = Batch(\n",
        "    surf_vars={\n",
        "        # First select the first two time points: 00:00 and 06:00. Afterwards, `[None]`\n",
        "        # inserts a batch dimension of size one.\n",
        "        \"2t\": torch.from_numpy(surf_vars_ds[\"t2m\"].values[:2][None]),\n",
        "        \"10u\": torch.from_numpy(surf_vars_ds[\"u10\"].values[:2][None]),\n",
        "        \"10v\": torch.from_numpy(surf_vars_ds[\"v10\"].values[:2][None]),\n",
        "        \"msl\": torch.from_numpy(surf_vars_ds[\"msl\"].values[:2][None]),\n",
        "    },\n",
        "    static_vars={\n",
        "        # The static variables are constant, so we just get them for the first time.\n",
        "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
        "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
        "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
        "    },\n",
        "    atmos_vars={\n",
        "        \"t\": torch.from_numpy(atmos_vars_ds[\"t\"].values[:2][None]),\n",
        "        \"u\": torch.from_numpy(atmos_vars_ds[\"u\"].values[:2][None]),\n",
        "        \"v\": torch.from_numpy(atmos_vars_ds[\"v\"].values[:2][None]),\n",
        "        \"q\": torch.from_numpy(atmos_vars_ds[\"q\"].values[:2][None]),\n",
        "        \"z\": torch.from_numpy(atmos_vars_ds[\"z\"].values[:2][None]),\n",
        "    },\n",
        "    metadata=Metadata(\n",
        "        lat=torch.from_numpy(surf_vars_ds.latitude.values),\n",
        "        lon=torch.from_numpy(surf_vars_ds.longitude.values),\n",
        "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
        "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
        "        # one value for every batch element. Select element 1, corresponding to time\n",
        "        # 06:00.\n",
        "        time=(surf_vars_ds.valid_time.values.astype(\"datetime64[s]\").tolist()[1],),\n",
        "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.pressure_level.values),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b6f12fe-1e49-49f0-bf03-bffcea9d1551",
      "metadata": {},
      "source": [
        "## Loading and Running the Model\n",
        "\n",
        "Finally, we are ready to load and run the model and visualise the predictions. We perform a roll-out for two steps, which produces predictions for hours 12:00 and 18:00.\n",
        "\n",
        "The model can be run locally, or [run on Azure AI Foundry](./foundry/intro.md). To run on Foundry, the environment variables `FOUNDRY_ENDPOINT`, `FOUNDRY_TOKEN`, and `BLOB_URL_WITH_SAS` need to be set. If you're unsure on how to set environment variables, see [here](./foundry/intro.md#accessing-environment-variables-in-a-jupyter-notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5084af5f-5a76-4309-b849-fa63cd426fcf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set to `False` to run locally and to `True` to run on Foundry.\n",
        "run_on_foundry = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4824be34-060d-422a-addf-841c2c3609b2",
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for Aurora:\n\tMissing key(s) in state_dict: \"backbone.encoder_layers.0.blocks.2.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.2.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.2.attn.qkv.weight\", \"backbone.encoder_layers.0.blocks.2.attn.qkv.bias\", \"backbone.encoder_layers.0.blocks.2.attn.proj.weight\", \"backbone.encoder_layers.0.blocks.2.attn.proj.bias\", \"backbone.encoder_layers.0.blocks.2.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.2.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.2.mlp.fc1.weight\", \"backbone.encoder_layers.0.blocks.2.mlp.fc1.bias\", \"backbone.encoder_layers.0.blocks.2.mlp.fc2.weight\", \"backbone.encoder_layers.0.blocks.2.mlp.fc2.bias\", \"backbone.encoder_layers.0.blocks.3.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.3.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.3.attn.qkv.weight\", \"backbone.encoder_layers.0.blocks.3.attn.qkv.bias\", \"backbone.encoder_layers.0.blocks.3.attn.proj.weight\", \"backbone.encoder_layers.0.blocks.3.attn.proj.bias\", \"backbone.encoder_layers.0.blocks.3.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.3.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.3.mlp.fc1.weight\", \"backbone.encoder_layers.0.blocks.3.mlp.fc1.bias\", \"backbone.encoder_layers.0.blocks.3.mlp.fc2.weight\", \"backbone.encoder_layers.0.blocks.3.mlp.fc2.bias\", \"backbone.encoder_layers.0.blocks.4.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.4.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.4.attn.qkv.weight\", \"backbone.encoder_layers.0.blocks.4.attn.qkv.bias\", \"backbone.encoder_layers.0.blocks.4.attn.proj.weight\", \"backbone.encoder_layers.0.blocks.4.attn.proj.bias\", \"backbone.encoder_layers.0.blocks.4.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.4.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.4.mlp.fc1.weight\", \"backbone.encoder_layers.0.blocks.4.mlp.fc1.bias\", \"backbone.encoder_layers.0.blocks.4.mlp.fc2.weight\", \"backbone.encoder_layers.0.blocks.4.mlp.fc2.bias\", \"backbone.encoder_layers.0.blocks.5.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.5.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.5.attn.qkv.weight\", \"backbone.encoder_layers.0.blocks.5.attn.qkv.bias\", \"backbone.encoder_layers.0.blocks.5.attn.proj.weight\", \"backbone.encoder_layers.0.blocks.5.attn.proj.bias\", \"backbone.encoder_layers.0.blocks.5.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.5.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.5.mlp.fc1.weight\", \"backbone.encoder_layers.0.blocks.5.mlp.fc1.bias\", \"backbone.encoder_layers.0.blocks.5.mlp.fc2.weight\", \"backbone.encoder_layers.0.blocks.5.mlp.fc2.bias\", \"backbone.encoder_layers.1.blocks.6.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.6.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.6.attn.qkv.weight\", \"backbone.encoder_layers.1.blocks.6.attn.qkv.bias\", \"backbone.encoder_layers.1.blocks.6.attn.proj.weight\", \"backbone.encoder_layers.1.blocks.6.attn.proj.bias\", \"backbone.encoder_layers.1.blocks.6.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.6.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.6.mlp.fc1.weight\", \"backbone.encoder_layers.1.blocks.6.mlp.fc1.bias\", \"backbone.encoder_layers.1.blocks.6.mlp.fc2.weight\", \"backbone.encoder_layers.1.blocks.6.mlp.fc2.bias\", \"backbone.encoder_layers.1.blocks.7.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.7.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.7.attn.qkv.weight\", \"backbone.encoder_layers.1.blocks.7.attn.qkv.bias\", \"backbone.encoder_layers.1.blocks.7.attn.proj.weight\", \"backbone.encoder_layers.1.blocks.7.attn.proj.bias\", \"backbone.encoder_layers.1.blocks.7.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.7.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.7.mlp.fc1.weight\", \"backbone.encoder_layers.1.blocks.7.mlp.fc1.bias\", \"backbone.encoder_layers.1.blocks.7.mlp.fc2.weight\", \"backbone.encoder_layers.1.blocks.7.mlp.fc2.bias\", \"backbone.encoder_layers.1.blocks.8.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.8.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.8.attn.qkv.weight\", \"backbone.encoder_layers.1.blocks.8.attn.qkv.bias\", \"backbone.encoder_layers.1.blocks.8.attn.proj.weight\", \"backbone.encoder_layers.1.blocks.8.attn.proj.bias\", \"backbone.encoder_layers.1.blocks.8.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.8.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.8.mlp.fc1.weight\", \"backbone.encoder_layers.1.blocks.8.mlp.fc1.bias\", \"backbone.encoder_layers.1.blocks.8.mlp.fc2.weight\", \"backbone.encoder_layers.1.blocks.8.mlp.fc2.bias\", \"backbone.encoder_layers.1.blocks.9.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.9.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.9.attn.qkv.weight\", \"backbone.encoder_layers.1.blocks.9.attn.qkv.bias\", \"backbone.encoder_layers.1.blocks.9.attn.proj.weight\", \"backbone.encoder_layers.1.blocks.9.attn.proj.bias\", \"backbone.encoder_layers.1.blocks.9.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.9.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.9.mlp.fc1.weight\", \"backbone.encoder_layers.1.blocks.9.mlp.fc1.bias\", \"backbone.encoder_layers.1.blocks.9.mlp.fc2.weight\", \"backbone.encoder_layers.1.blocks.9.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.2.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.2.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.2.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.2.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.2.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.2.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.2.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.2.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.2.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.2.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.2.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.2.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.3.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.3.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.3.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.3.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.3.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.3.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.3.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.3.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.3.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.3.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.3.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.3.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.4.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.4.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.4.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.4.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.4.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.4.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.4.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.4.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.4.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.4.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.4.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.4.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.5.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.5.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.5.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.5.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.5.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.5.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.5.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.5.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.5.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.5.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.5.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.5.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.6.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.6.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.6.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.6.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.6.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.6.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.6.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.6.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.6.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.6.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.6.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.6.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.7.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.7.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.7.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.7.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.7.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.7.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.7.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.7.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.7.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.7.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.7.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.7.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.2.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.2.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.2.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.2.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.2.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.2.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.2.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.2.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.2.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.2.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.2.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.2.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.3.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.3.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.3.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.3.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.3.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.3.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.3.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.3.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.3.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.3.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.3.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.3.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.4.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.4.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.4.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.4.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.4.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.4.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.4.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.4.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.4.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.4.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.4.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.4.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.5.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.5.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.5.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.5.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.5.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.5.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.5.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.5.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.5.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.5.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.5.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.5.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.6.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.6.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.6.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.6.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.6.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.6.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.6.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.6.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.6.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.6.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.6.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.6.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.7.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.7.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.7.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.7.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.7.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.7.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.7.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.7.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.7.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.7.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.7.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.7.mlp.fc2.bias\", \"backbone.decoder_layers.1.blocks.6.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.6.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.6.attn.qkv.weight\", \"backbone.decoder_layers.1.blocks.6.attn.qkv.bias\", \"backbone.decoder_layers.1.blocks.6.attn.proj.weight\", \"backbone.decoder_layers.1.blocks.6.attn.proj.bias\", \"backbone.decoder_layers.1.blocks.6.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.6.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.6.mlp.fc1.weight\", \"backbone.decoder_layers.1.blocks.6.mlp.fc1.bias\", \"backbone.decoder_layers.1.blocks.6.mlp.fc2.weight\", \"backbone.decoder_layers.1.blocks.6.mlp.fc2.bias\", \"backbone.decoder_layers.1.blocks.7.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.7.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.7.attn.qkv.weight\", \"backbone.decoder_layers.1.blocks.7.attn.qkv.bias\", \"backbone.decoder_layers.1.blocks.7.attn.proj.weight\", \"backbone.decoder_layers.1.blocks.7.attn.proj.bias\", \"backbone.decoder_layers.1.blocks.7.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.7.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.7.mlp.fc1.weight\", \"backbone.decoder_layers.1.blocks.7.mlp.fc1.bias\", \"backbone.decoder_layers.1.blocks.7.mlp.fc2.weight\", \"backbone.decoder_layers.1.blocks.7.mlp.fc2.bias\", \"backbone.decoder_layers.1.blocks.8.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.8.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.8.attn.qkv.weight\", \"backbone.decoder_layers.1.blocks.8.attn.qkv.bias\", \"backbone.decoder_layers.1.blocks.8.attn.proj.weight\", \"backbone.decoder_layers.1.blocks.8.attn.proj.bias\", \"backbone.decoder_layers.1.blocks.8.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.8.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.8.mlp.fc1.weight\", \"backbone.decoder_layers.1.blocks.8.mlp.fc1.bias\", \"backbone.decoder_layers.1.blocks.8.mlp.fc2.weight\", \"backbone.decoder_layers.1.blocks.8.mlp.fc2.bias\", \"backbone.decoder_layers.1.blocks.9.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.9.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.9.attn.qkv.weight\", \"backbone.decoder_layers.1.blocks.9.attn.qkv.bias\", \"backbone.decoder_layers.1.blocks.9.attn.proj.weight\", \"backbone.decoder_layers.1.blocks.9.attn.proj.bias\", \"backbone.decoder_layers.1.blocks.9.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.9.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.9.mlp.fc1.weight\", \"backbone.decoder_layers.1.blocks.9.mlp.fc1.bias\", \"backbone.decoder_layers.1.blocks.9.mlp.fc2.weight\", \"backbone.decoder_layers.1.blocks.9.mlp.fc2.bias\", \"backbone.decoder_layers.2.blocks.2.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.2.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.2.attn.qkv.weight\", \"backbone.decoder_layers.2.blocks.2.attn.qkv.bias\", \"backbone.decoder_layers.2.blocks.2.attn.proj.weight\", \"backbone.decoder_layers.2.blocks.2.attn.proj.bias\", \"backbone.decoder_layers.2.blocks.2.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.2.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.2.mlp.fc1.weight\", \"backbone.decoder_layers.2.blocks.2.mlp.fc1.bias\", \"backbone.decoder_layers.2.blocks.2.mlp.fc2.weight\", \"backbone.decoder_layers.2.blocks.2.mlp.fc2.bias\", \"backbone.decoder_layers.2.blocks.3.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.3.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.3.attn.qkv.weight\", \"backbone.decoder_layers.2.blocks.3.attn.qkv.bias\", \"backbone.decoder_layers.2.blocks.3.attn.proj.weight\", \"backbone.decoder_layers.2.blocks.3.attn.proj.bias\", \"backbone.decoder_layers.2.blocks.3.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.3.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.3.mlp.fc1.weight\", \"backbone.decoder_layers.2.blocks.3.mlp.fc1.bias\", \"backbone.decoder_layers.2.blocks.3.mlp.fc2.weight\", \"backbone.decoder_layers.2.blocks.3.mlp.fc2.bias\", \"backbone.decoder_layers.2.blocks.4.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.4.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.4.attn.qkv.weight\", \"backbone.decoder_layers.2.blocks.4.attn.qkv.bias\", \"backbone.decoder_layers.2.blocks.4.attn.proj.weight\", \"backbone.decoder_layers.2.blocks.4.attn.proj.bias\", \"backbone.decoder_layers.2.blocks.4.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.4.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.4.mlp.fc1.weight\", \"backbone.decoder_layers.2.blocks.4.mlp.fc1.bias\", \"backbone.decoder_layers.2.blocks.4.mlp.fc2.weight\", \"backbone.decoder_layers.2.blocks.4.mlp.fc2.bias\", \"backbone.decoder_layers.2.blocks.5.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.5.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.5.attn.qkv.weight\", \"backbone.decoder_layers.2.blocks.5.attn.qkv.bias\", \"backbone.decoder_layers.2.blocks.5.attn.proj.weight\", \"backbone.decoder_layers.2.blocks.5.attn.proj.bias\", \"backbone.decoder_layers.2.blocks.5.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.5.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.5.mlp.fc1.weight\", \"backbone.decoder_layers.2.blocks.5.mlp.fc1.bias\", \"backbone.decoder_layers.2.blocks.5.mlp.fc2.weight\", \"backbone.decoder_layers.2.blocks.5.mlp.fc2.bias\". \n\tsize mismatch for encoder.atmos_latents: copying a param with shape torch.Size([3, 256]) from checkpoint, the shape in current model is torch.Size([3, 512]).\n\tsize mismatch for encoder.surf_level_encoding: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_mlp.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for encoder.surf_mlp.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.surf_mlp.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for encoder.surf_mlp.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.pos_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.pos_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.scale_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.scale_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.lead_time_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.lead_time_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.absolute_time_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.absolute_time_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.atmos_levels_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.atmos_levels_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_token_embeds.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_token_embeds.weights.10u: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.10v: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.2t: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.lsm: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.msl: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.slt: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.z: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.q: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.t: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.u: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.v: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.z: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.level_agg.layers.0.0.to_q.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.level_agg.layers.0.0.to_kv.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for encoder.level_agg.layers.0.0.to_out.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.level_agg.layers.0.1.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for encoder.level_agg.layers.0.1.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.level_agg.layers.0.1.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for encoder.level_agg.layers.0.1.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.level_agg.layers.0.2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.level_agg.layers.0.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.level_agg.layers.0.3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.level_agg.layers.0.3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.time_mlp.0.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.time_mlp.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.time_mlp.2.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.time_mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.downsample.reduction.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for backbone.encoder_layers.0.downsample.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.0.downsample.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.downsample.reduction.weight: copying a param with shape torch.Size([1024, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.downsample.norm.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.downsample.norm.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.upsample.lin1.weight: copying a param with shape torch.Size([2048, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.upsample.lin2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.0.upsample.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.0.upsample.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.upsample.lin1.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.upsample.lin2.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.decoder_layers.1.upsample.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.1.upsample.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.level_decoder.layers.0.0.to_q.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.0.to_kv.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.0.to_out.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.1.net.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.1.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for decoder.level_decoder.layers.0.1.net.2.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for decoder.level_decoder.layers.0.1.net.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.3.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.surf_heads.10u.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.surf_heads.10v.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.surf_heads.2t.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.surf_heads.msl.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.q.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.t.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.u.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.v.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.z.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_levels_embed.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for decoder.atmos_levels_embed.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maurora\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Aurora, rollout\n\u001b[32m      4\u001b[39m model = Aurora(use_lora=\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# The pretrained version does not use LoRA.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/aurora\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maurora-0.25-small-pretrained.ckpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m model.eval()\n\u001b[32m      8\u001b[39m model = model.to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\aurora\\model\\aurora.py:433\u001b[39m, in \u001b[36mAurora.load_checkpoint\u001b[39m\u001b[34m(self, repo, name, strict)\u001b[39m\n\u001b[32m    431\u001b[39m name = name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_checkpoint_name\n\u001b[32m    432\u001b[39m path = hf_hub_download(repo_id=repo, filename=name)\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_checkpoint_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\aurora\\model\\aurora.py:459\u001b[39m, in \u001b[36mAurora.load_checkpoint_local\u001b[39m\u001b[34m(self, path, strict)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_history_size < current_history_size:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    455\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot load checkpoint with `max_history_size` \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_history_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    456\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minto model with `max_history_size` \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.max_history_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    457\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for Aurora:\n\tMissing key(s) in state_dict: \"backbone.encoder_layers.0.blocks.2.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.2.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.2.attn.qkv.weight\", \"backbone.encoder_layers.0.blocks.2.attn.qkv.bias\", \"backbone.encoder_layers.0.blocks.2.attn.proj.weight\", \"backbone.encoder_layers.0.blocks.2.attn.proj.bias\", \"backbone.encoder_layers.0.blocks.2.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.2.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.2.mlp.fc1.weight\", \"backbone.encoder_layers.0.blocks.2.mlp.fc1.bias\", \"backbone.encoder_layers.0.blocks.2.mlp.fc2.weight\", \"backbone.encoder_layers.0.blocks.2.mlp.fc2.bias\", \"backbone.encoder_layers.0.blocks.3.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.3.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.3.attn.qkv.weight\", \"backbone.encoder_layers.0.blocks.3.attn.qkv.bias\", \"backbone.encoder_layers.0.blocks.3.attn.proj.weight\", \"backbone.encoder_layers.0.blocks.3.attn.proj.bias\", \"backbone.encoder_layers.0.blocks.3.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.3.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.3.mlp.fc1.weight\", \"backbone.encoder_layers.0.blocks.3.mlp.fc1.bias\", \"backbone.encoder_layers.0.blocks.3.mlp.fc2.weight\", \"backbone.encoder_layers.0.blocks.3.mlp.fc2.bias\", \"backbone.encoder_layers.0.blocks.4.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.4.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.4.attn.qkv.weight\", \"backbone.encoder_layers.0.blocks.4.attn.qkv.bias\", \"backbone.encoder_layers.0.blocks.4.attn.proj.weight\", \"backbone.encoder_layers.0.blocks.4.attn.proj.bias\", \"backbone.encoder_layers.0.blocks.4.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.4.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.4.mlp.fc1.weight\", \"backbone.encoder_layers.0.blocks.4.mlp.fc1.bias\", \"backbone.encoder_layers.0.blocks.4.mlp.fc2.weight\", \"backbone.encoder_layers.0.blocks.4.mlp.fc2.bias\", \"backbone.encoder_layers.0.blocks.5.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.5.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.5.attn.qkv.weight\", \"backbone.encoder_layers.0.blocks.5.attn.qkv.bias\", \"backbone.encoder_layers.0.blocks.5.attn.proj.weight\", \"backbone.encoder_layers.0.blocks.5.attn.proj.bias\", \"backbone.encoder_layers.0.blocks.5.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.0.blocks.5.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.0.blocks.5.mlp.fc1.weight\", \"backbone.encoder_layers.0.blocks.5.mlp.fc1.bias\", \"backbone.encoder_layers.0.blocks.5.mlp.fc2.weight\", \"backbone.encoder_layers.0.blocks.5.mlp.fc2.bias\", \"backbone.encoder_layers.1.blocks.6.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.6.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.6.attn.qkv.weight\", \"backbone.encoder_layers.1.blocks.6.attn.qkv.bias\", \"backbone.encoder_layers.1.blocks.6.attn.proj.weight\", \"backbone.encoder_layers.1.blocks.6.attn.proj.bias\", \"backbone.encoder_layers.1.blocks.6.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.6.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.6.mlp.fc1.weight\", \"backbone.encoder_layers.1.blocks.6.mlp.fc1.bias\", \"backbone.encoder_layers.1.blocks.6.mlp.fc2.weight\", \"backbone.encoder_layers.1.blocks.6.mlp.fc2.bias\", \"backbone.encoder_layers.1.blocks.7.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.7.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.7.attn.qkv.weight\", \"backbone.encoder_layers.1.blocks.7.attn.qkv.bias\", \"backbone.encoder_layers.1.blocks.7.attn.proj.weight\", \"backbone.encoder_layers.1.blocks.7.attn.proj.bias\", \"backbone.encoder_layers.1.blocks.7.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.7.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.7.mlp.fc1.weight\", \"backbone.encoder_layers.1.blocks.7.mlp.fc1.bias\", \"backbone.encoder_layers.1.blocks.7.mlp.fc2.weight\", \"backbone.encoder_layers.1.blocks.7.mlp.fc2.bias\", \"backbone.encoder_layers.1.blocks.8.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.8.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.8.attn.qkv.weight\", \"backbone.encoder_layers.1.blocks.8.attn.qkv.bias\", \"backbone.encoder_layers.1.blocks.8.attn.proj.weight\", \"backbone.encoder_layers.1.blocks.8.attn.proj.bias\", \"backbone.encoder_layers.1.blocks.8.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.8.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.8.mlp.fc1.weight\", \"backbone.encoder_layers.1.blocks.8.mlp.fc1.bias\", \"backbone.encoder_layers.1.blocks.8.mlp.fc2.weight\", \"backbone.encoder_layers.1.blocks.8.mlp.fc2.bias\", \"backbone.encoder_layers.1.blocks.9.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.9.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.9.attn.qkv.weight\", \"backbone.encoder_layers.1.blocks.9.attn.qkv.bias\", \"backbone.encoder_layers.1.blocks.9.attn.proj.weight\", \"backbone.encoder_layers.1.blocks.9.attn.proj.bias\", \"backbone.encoder_layers.1.blocks.9.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.1.blocks.9.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.1.blocks.9.mlp.fc1.weight\", \"backbone.encoder_layers.1.blocks.9.mlp.fc1.bias\", \"backbone.encoder_layers.1.blocks.9.mlp.fc2.weight\", \"backbone.encoder_layers.1.blocks.9.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.2.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.2.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.2.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.2.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.2.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.2.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.2.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.2.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.2.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.2.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.2.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.2.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.3.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.3.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.3.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.3.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.3.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.3.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.3.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.3.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.3.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.3.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.3.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.3.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.4.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.4.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.4.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.4.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.4.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.4.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.4.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.4.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.4.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.4.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.4.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.4.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.5.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.5.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.5.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.5.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.5.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.5.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.5.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.5.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.5.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.5.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.5.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.5.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.6.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.6.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.6.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.6.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.6.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.6.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.6.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.6.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.6.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.6.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.6.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.6.mlp.fc2.bias\", \"backbone.encoder_layers.2.blocks.7.norm1.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.7.norm1.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.7.attn.qkv.weight\", \"backbone.encoder_layers.2.blocks.7.attn.qkv.bias\", \"backbone.encoder_layers.2.blocks.7.attn.proj.weight\", \"backbone.encoder_layers.2.blocks.7.attn.proj.bias\", \"backbone.encoder_layers.2.blocks.7.norm2.ln_modulation.1.weight\", \"backbone.encoder_layers.2.blocks.7.norm2.ln_modulation.1.bias\", \"backbone.encoder_layers.2.blocks.7.mlp.fc1.weight\", \"backbone.encoder_layers.2.blocks.7.mlp.fc1.bias\", \"backbone.encoder_layers.2.blocks.7.mlp.fc2.weight\", \"backbone.encoder_layers.2.blocks.7.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.2.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.2.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.2.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.2.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.2.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.2.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.2.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.2.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.2.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.2.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.2.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.2.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.3.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.3.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.3.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.3.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.3.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.3.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.3.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.3.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.3.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.3.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.3.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.3.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.4.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.4.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.4.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.4.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.4.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.4.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.4.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.4.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.4.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.4.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.4.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.4.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.5.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.5.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.5.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.5.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.5.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.5.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.5.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.5.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.5.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.5.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.5.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.5.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.6.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.6.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.6.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.6.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.6.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.6.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.6.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.6.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.6.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.6.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.6.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.6.mlp.fc2.bias\", \"backbone.decoder_layers.0.blocks.7.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.7.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.7.attn.qkv.weight\", \"backbone.decoder_layers.0.blocks.7.attn.qkv.bias\", \"backbone.decoder_layers.0.blocks.7.attn.proj.weight\", \"backbone.decoder_layers.0.blocks.7.attn.proj.bias\", \"backbone.decoder_layers.0.blocks.7.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.0.blocks.7.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.0.blocks.7.mlp.fc1.weight\", \"backbone.decoder_layers.0.blocks.7.mlp.fc1.bias\", \"backbone.decoder_layers.0.blocks.7.mlp.fc2.weight\", \"backbone.decoder_layers.0.blocks.7.mlp.fc2.bias\", \"backbone.decoder_layers.1.blocks.6.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.6.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.6.attn.qkv.weight\", \"backbone.decoder_layers.1.blocks.6.attn.qkv.bias\", \"backbone.decoder_layers.1.blocks.6.attn.proj.weight\", \"backbone.decoder_layers.1.blocks.6.attn.proj.bias\", \"backbone.decoder_layers.1.blocks.6.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.6.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.6.mlp.fc1.weight\", \"backbone.decoder_layers.1.blocks.6.mlp.fc1.bias\", \"backbone.decoder_layers.1.blocks.6.mlp.fc2.weight\", \"backbone.decoder_layers.1.blocks.6.mlp.fc2.bias\", \"backbone.decoder_layers.1.blocks.7.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.7.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.7.attn.qkv.weight\", \"backbone.decoder_layers.1.blocks.7.attn.qkv.bias\", \"backbone.decoder_layers.1.blocks.7.attn.proj.weight\", \"backbone.decoder_layers.1.blocks.7.attn.proj.bias\", \"backbone.decoder_layers.1.blocks.7.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.7.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.7.mlp.fc1.weight\", \"backbone.decoder_layers.1.blocks.7.mlp.fc1.bias\", \"backbone.decoder_layers.1.blocks.7.mlp.fc2.weight\", \"backbone.decoder_layers.1.blocks.7.mlp.fc2.bias\", \"backbone.decoder_layers.1.blocks.8.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.8.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.8.attn.qkv.weight\", \"backbone.decoder_layers.1.blocks.8.attn.qkv.bias\", \"backbone.decoder_layers.1.blocks.8.attn.proj.weight\", \"backbone.decoder_layers.1.blocks.8.attn.proj.bias\", \"backbone.decoder_layers.1.blocks.8.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.8.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.8.mlp.fc1.weight\", \"backbone.decoder_layers.1.blocks.8.mlp.fc1.bias\", \"backbone.decoder_layers.1.blocks.8.mlp.fc2.weight\", \"backbone.decoder_layers.1.blocks.8.mlp.fc2.bias\", \"backbone.decoder_layers.1.blocks.9.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.9.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.9.attn.qkv.weight\", \"backbone.decoder_layers.1.blocks.9.attn.qkv.bias\", \"backbone.decoder_layers.1.blocks.9.attn.proj.weight\", \"backbone.decoder_layers.1.blocks.9.attn.proj.bias\", \"backbone.decoder_layers.1.blocks.9.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.1.blocks.9.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.1.blocks.9.mlp.fc1.weight\", \"backbone.decoder_layers.1.blocks.9.mlp.fc1.bias\", \"backbone.decoder_layers.1.blocks.9.mlp.fc2.weight\", \"backbone.decoder_layers.1.blocks.9.mlp.fc2.bias\", \"backbone.decoder_layers.2.blocks.2.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.2.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.2.attn.qkv.weight\", \"backbone.decoder_layers.2.blocks.2.attn.qkv.bias\", \"backbone.decoder_layers.2.blocks.2.attn.proj.weight\", \"backbone.decoder_layers.2.blocks.2.attn.proj.bias\", \"backbone.decoder_layers.2.blocks.2.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.2.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.2.mlp.fc1.weight\", \"backbone.decoder_layers.2.blocks.2.mlp.fc1.bias\", \"backbone.decoder_layers.2.blocks.2.mlp.fc2.weight\", \"backbone.decoder_layers.2.blocks.2.mlp.fc2.bias\", \"backbone.decoder_layers.2.blocks.3.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.3.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.3.attn.qkv.weight\", \"backbone.decoder_layers.2.blocks.3.attn.qkv.bias\", \"backbone.decoder_layers.2.blocks.3.attn.proj.weight\", \"backbone.decoder_layers.2.blocks.3.attn.proj.bias\", \"backbone.decoder_layers.2.blocks.3.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.3.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.3.mlp.fc1.weight\", \"backbone.decoder_layers.2.blocks.3.mlp.fc1.bias\", \"backbone.decoder_layers.2.blocks.3.mlp.fc2.weight\", \"backbone.decoder_layers.2.blocks.3.mlp.fc2.bias\", \"backbone.decoder_layers.2.blocks.4.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.4.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.4.attn.qkv.weight\", \"backbone.decoder_layers.2.blocks.4.attn.qkv.bias\", \"backbone.decoder_layers.2.blocks.4.attn.proj.weight\", \"backbone.decoder_layers.2.blocks.4.attn.proj.bias\", \"backbone.decoder_layers.2.blocks.4.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.4.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.4.mlp.fc1.weight\", \"backbone.decoder_layers.2.blocks.4.mlp.fc1.bias\", \"backbone.decoder_layers.2.blocks.4.mlp.fc2.weight\", \"backbone.decoder_layers.2.blocks.4.mlp.fc2.bias\", \"backbone.decoder_layers.2.blocks.5.norm1.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.5.norm1.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.5.attn.qkv.weight\", \"backbone.decoder_layers.2.blocks.5.attn.qkv.bias\", \"backbone.decoder_layers.2.blocks.5.attn.proj.weight\", \"backbone.decoder_layers.2.blocks.5.attn.proj.bias\", \"backbone.decoder_layers.2.blocks.5.norm2.ln_modulation.1.weight\", \"backbone.decoder_layers.2.blocks.5.norm2.ln_modulation.1.bias\", \"backbone.decoder_layers.2.blocks.5.mlp.fc1.weight\", \"backbone.decoder_layers.2.blocks.5.mlp.fc1.bias\", \"backbone.decoder_layers.2.blocks.5.mlp.fc2.weight\", \"backbone.decoder_layers.2.blocks.5.mlp.fc2.bias\". \n\tsize mismatch for encoder.atmos_latents: copying a param with shape torch.Size([3, 256]) from checkpoint, the shape in current model is torch.Size([3, 512]).\n\tsize mismatch for encoder.surf_level_encoding: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_mlp.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for encoder.surf_mlp.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.surf_mlp.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for encoder.surf_mlp.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.pos_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.pos_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.scale_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.scale_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.lead_time_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.lead_time_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.absolute_time_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.absolute_time_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.atmos_levels_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.atmos_levels_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_token_embeds.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.surf_token_embeds.weights.10u: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.10v: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.2t: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.lsm: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.msl: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.slt: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.surf_token_embeds.weights.z: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.q: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.t: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.u: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.v: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.atmos_token_embeds.weights.z: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n\tsize mismatch for encoder.level_agg.layers.0.0.to_q.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.level_agg.layers.0.0.to_kv.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for encoder.level_agg.layers.0.0.to_out.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.level_agg.layers.0.1.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for encoder.level_agg.layers.0.1.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.level_agg.layers.0.1.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for encoder.level_agg.layers.0.1.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.level_agg.layers.0.2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.level_agg.layers.0.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.level_agg.layers.0.3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.level_agg.layers.0.3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.time_mlp.0.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.time_mlp.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.time_mlp.2.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.time_mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for backbone.encoder_layers.0.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.encoder_layers.0.downsample.reduction.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for backbone.encoder_layers.0.downsample.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.0.downsample.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.encoder_layers.1.downsample.reduction.weight: copying a param with shape torch.Size([1024, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 4096]).\n\tsize mismatch for backbone.encoder_layers.1.downsample.norm.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.1.downsample.norm.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n\tsize mismatch for backbone.encoder_layers.2.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n\tsize mismatch for backbone.decoder_layers.0.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.0.upsample.lin1.weight: copying a param with shape torch.Size([2048, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 2048]).\n\tsize mismatch for backbone.decoder_layers.0.upsample.lin2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.0.upsample.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.0.upsample.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for backbone.decoder_layers.1.blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.1.upsample.lin1.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for backbone.decoder_layers.1.upsample.lin2.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.decoder_layers.1.upsample.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.1.upsample.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n\tsize mismatch for backbone.decoder_layers.2.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.level_decoder.layers.0.0.to_q.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.0.to_kv.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.0.to_out.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.1.net.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.1.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for decoder.level_decoder.layers.0.1.net.2.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for decoder.level_decoder.layers.0.1.net.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.3.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.level_decoder.layers.0.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.surf_heads.10u.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.surf_heads.10v.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.surf_heads.2t.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.surf_heads.msl.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.q.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.t.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.u.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.v.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_heads.z.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n\tsize mismatch for decoder.atmos_levels_embed.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for decoder.atmos_levels_embed.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024])."
          ]
        }
      ],
      "source": [
        "if not run_on_foundry:\n",
        "    from aurora import Aurora, rollout\n",
        "\n",
        "    model = Aurora(use_lora=False)  # The pretrained version does not use LoRA.\n",
        "    model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\")\n",
        "\n",
        "    model.eval()\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        preds = [pred.to(\"cpu\") for pred in rollout(model, batch, steps=2)]\n",
        "\n",
        "    model = model.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58810cdf-3889-42f0-a9e6-1ce786e3cf6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "if run_on_foundry:\n",
        "    import logging\n",
        "    import os\n",
        "    import warnings\n",
        "\n",
        "    from aurora.foundry import BlobStorageChannel, FoundryClient, submit\n",
        "\n",
        "    # In this demo, we silence all warnings.\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    # But we do want to show what's happening under the hood!\n",
        "    logging.basicConfig(level=logging.WARNING, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "    logging.getLogger(\"aurora\").setLevel(logging.INFO)\n",
        "\n",
        "    foundry_client = FoundryClient(\n",
        "        endpoint=os.environ[\"FOUNDRY_ENDPOINT\"],\n",
        "        token=os.environ[\"FOUNDRY_TOKEN\"],\n",
        "    )\n",
        "    channel = BlobStorageChannel(os.environ[\"BLOB_URL_WITH_SAS\"])\n",
        "\n",
        "    predictions = list(\n",
        "        submit(\n",
        "            batch,\n",
        "            model_name=\"aurora-0.25-pretrained\",\n",
        "            num_steps=2,\n",
        "            foundry_client=foundry_client,\n",
        "            channel=channel,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6e84170-5802-46ad-b4d8-6eb9bf8c98ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize=(12, 6.5))\n",
        "\n",
        "for i in range(ax.shape[0]):\n",
        "    pred = preds[i]\n",
        "\n",
        "    ax[i, 0].imshow(pred.surf_vars[\"2t\"][0, 0].numpy() - 273.15, vmin=-50, vmax=50)\n",
        "    ax[i, 0].set_ylabel(str(pred.metadata.time[0]))\n",
        "    if i == 0:\n",
        "        ax[i, 0].set_title(\"Aurora Prediction\")\n",
        "    ax[i, 0].set_xticks([])\n",
        "    ax[i, 0].set_yticks([])\n",
        "\n",
        "    ax[i, 1].imshow(surf_vars_ds[\"t2m\"][2 + i].values - 273.15, vmin=-50, vmax=50)\n",
        "    if i == 0:\n",
        "        ax[i, 1].set_title(\"ERA5\")\n",
        "    ax[i, 1].set_xticks([])\n",
        "    ax[i, 1].set_yticks([])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61df0128-146b-4721-b734-1143956c9582",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
