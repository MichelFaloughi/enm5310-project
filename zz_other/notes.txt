surface variables: is a dict with keys (2t, 10u, v10, msl)
each key maps to a tensor of shape (a, b, c, d)

2t: 2 m temperature
10u: 10 m u-component of wind
v10: 10 m v-component of wind
msl: mean sea level pressure

Each surface variables tensor has shape (a, b, c, d) where:
a: batch size (number of samples)
b: time steps
c: latitude
d: longitude

static variables: is a dict with keys (lsm, z, slt)
each key maps to a tensor of shape (a, b)

lsm: land-sea mask (0=sea, 1=land)
z: geopotential height (elevation)
slt: soil type

Each static variables tensor has shape (a, b) where:
a: latitude
b: longitude

atmospheric variables:
z: geopotential height
u: u-component of wind
v: v-component of wind
t: temperature
q: specific humidity

Each atmospheric variables tensor has shape (a, b, c, d, e) where:
a: batch size
b: time steps
c, number of atmospheric pressure levels
d: latitude
e: longitude

metadata=Metadata(
        lat=torch.linspace(90, -90, 17),
        lon=torch.linspace(0, 360, 32 + 1)[:-1],
        time=(datetime(2020, 6, 1, 12, 0),),
        atmos_levels=(100, 250, 500, 850),
    )
This defines the coordinate metadata for your batch:
- lat: 17 latitudes from 90° N to −90° S
- lon: 32 longitudes from 0° to 360° (excluding the duplicate at 360°)
- time: just one timestamp (2020-06-01 12:00 UTC)
- atmos_levels: pressure levels (hPa)

The model uses this metadata to understand where and when each grid point lies.

---

btw, prediction variables are:
tp → total precipitation
pr → precipitation rate
rain_rate → rain rate
GraphCast, Pangu-Weather, FourCastNet, and some other models predict some of these variables
aurora doesn't


btw, for atmospheric pressure levels: (hPa = hectopascals)
100 hPa → lower stratosphere
250 hPa → upper troposphere (jet level)
500 hPa → mid-troposphere
850 hPa → lower troposphere





model.load_checkpoint("microsoft/aurora", "aurora-0.25-small-pretrained.ckpt")

the documentation for this function is:
def load_checkpoint(
        self,
        repo: Optional[str] = None,
        name: Optional[str] = None,
        revision: Optional[str] = None,
        strict: bool = True,
    ) -> None:
        """Load a checkpoint from HuggingFace.

        Args:
            repo (str, optional): Name of the repository of the form `user/repo`.
            name (str, optional): Path to the checkpoint relative to the root of the repository,
                e.g. `checkpoint.cpkt`.
            revision (str, optional): Version hash of the Huggingface git repository commit.
            strict (bool, optional): Error if the model parameters are not exactly equal to the
                parameters in the checkpoint. Defaults to `True`.
        """
        repo = repo or self.default_checkpoint_repo
        name = name or self.default_checkpoint_name
        revision = revision or self.default_checkpoint_revision
        path = hf_hub_download(repo_id=repo, filename=name, revision=revision)
        self.load_checkpoint_local(path, strict=strict)




model.eval() sets the model to evaluation mode (disables dropout, etc.)
this means we're done training and just want to make predictions (inference)

with torch.inference_mode(): is a context manager that disables gradient calculations
this saves memory and speeds up computations during inference since we don't need gradients