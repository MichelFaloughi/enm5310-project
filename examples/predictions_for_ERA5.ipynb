{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7d81b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is failing on boulmich_beast"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f57a10-13a1-4f66-a734-065fc16b17b2",
      "metadata": {},
      "source": [
        "# Predictions for ERA5\n",
        "\n",
        "In this example, we will download ERA5 data for 1 Jan 2023 at 0.25 degrees resolution and run Aurora on this data. The fine-tuned version of Aurora specifically only works with IFS HRES T0, so we use the non-fine-tuned version of Aurora in this example.\n",
        "\n",
        "Running this notebook requires additional Python packages. You can install these as follows:\n",
        "\n",
        "```\n",
        "pip install cdsapi matplotlib\n",
        "```\n",
        "\n",
        "## Downloading the Data\n",
        "\n",
        "To begin with, register an account with the [Climate Data Store](https://cds.climate.copernicus.eu/) and create `$HOME/.cdsapirc` with the following content:\n",
        "\n",
        "```\n",
        "url: https://cds.climate.copernicus.eu/api\n",
        "key: <API key>\n",
        "```\n",
        "\n",
        "You can find your API key on your account page.\n",
        "\n",
        "In order to be able to download ERA5 data, you need to accept the terms of use in the [dataset page](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=download).\n",
        "\n",
        "We now download the ERA5 data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0541bf19-024f-4c76-8666-9d559640156e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Static variables downloaded!\n",
            "Surface-level variables downloaded!\n",
            "Atmospheric variables downloaded!\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import cdsapi\n",
        "\n",
        "# Data will be downloaded here.\n",
        "download_path = Path(\"~/downloads/era5\")\n",
        "\n",
        "c = cdsapi.Client()\n",
        "\n",
        "download_path = download_path.expanduser()\n",
        "download_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download the static variables.\n",
        "if not (download_path / \"static.nc\").exists():\n",
        "    c.retrieve(\n",
        "        \"reanalysis-era5-single-levels\",\n",
        "        {\n",
        "            \"product_type\": \"reanalysis\",\n",
        "            \"variable\": [\n",
        "                \"geopotential\",\n",
        "                \"land_sea_mask\",\n",
        "                \"soil_type\",\n",
        "            ],\n",
        "            \"year\": \"2023\",\n",
        "            \"month\": \"01\",\n",
        "            \"day\": \"01\",\n",
        "            \"time\": \"00:00\",\n",
        "            \"format\": \"netcdf\",\n",
        "        },\n",
        "        str(download_path / \"static.nc\"),\n",
        "    )\n",
        "print(\"Static variables downloaded!\")\n",
        "\n",
        "# Download the surface-level variables.\n",
        "if not (download_path / \"2023-01-01-surface-level.nc\").exists():\n",
        "    c.retrieve(\n",
        "        \"reanalysis-era5-single-levels\",\n",
        "        {\n",
        "            \"product_type\": \"reanalysis\",\n",
        "            \"variable\": [\n",
        "                \"2m_temperature\",\n",
        "                \"10m_u_component_of_wind\",\n",
        "                \"10m_v_component_of_wind\",\n",
        "                \"mean_sea_level_pressure\",\n",
        "            ],\n",
        "            \"year\": \"2023\",\n",
        "            \"month\": \"01\",\n",
        "            \"day\": \"01\",\n",
        "            \"time\": [\"00:00\", \"06:00\", \"12:00\", \"18:00\"],\n",
        "            \"format\": \"netcdf\",\n",
        "        },\n",
        "        str(download_path / \"2023-01-01-surface-level.nc\"),\n",
        "    )\n",
        "print(\"Surface-level variables downloaded!\")\n",
        "\n",
        "# Download the atmospheric variables.\n",
        "if not (download_path / \"2023-01-01-atmospheric.nc\").exists():\n",
        "    c.retrieve(\n",
        "        \"reanalysis-era5-pressure-levels\",\n",
        "        {\n",
        "            \"product_type\": \"reanalysis\",\n",
        "            \"variable\": [\n",
        "                \"temperature\",\n",
        "                \"u_component_of_wind\",\n",
        "                \"v_component_of_wind\",\n",
        "                \"specific_humidity\",\n",
        "                \"geopotential\",\n",
        "            ],\n",
        "            \"pressure_level\": [\n",
        "                \"50\",\n",
        "                \"100\",\n",
        "                \"150\",\n",
        "                \"200\",\n",
        "                \"250\",\n",
        "                \"300\",\n",
        "                \"400\",\n",
        "                \"500\",\n",
        "                \"600\",\n",
        "                \"700\",\n",
        "                \"850\",\n",
        "                \"925\",\n",
        "                \"1000\",\n",
        "            ],\n",
        "            \"year\": \"2023\",\n",
        "            \"month\": \"01\",\n",
        "            \"day\": \"01\",\n",
        "            \"time\": [\"00:00\", \"06:00\", \"12:00\", \"18:00\"],\n",
        "            \"format\": \"netcdf\",\n",
        "        },\n",
        "        str(download_path / \"2023-01-01-atmospheric.nc\"),\n",
        "    )\n",
        "print(\"Atmospheric variables downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7d8aa4-a16b-481c-b7e5-66764d6e98f1",
      "metadata": {},
      "source": [
        "## Preparing a Batch\n",
        "\n",
        "We convert the downloaded data to an `aurora.Batch`, which is what the model requires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fba4fb22-475b-4156-94c8-e61c77a20539",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import xarray as xr\n",
        "\n",
        "from aurora import Batch, Metadata\n",
        "\n",
        "static_vars_ds = xr.open_dataset(download_path / \"static.nc\", engine=\"netcdf4\")\n",
        "surf_vars_ds = xr.open_dataset(download_path / \"2023-01-01-surface-level.nc\", engine=\"netcdf4\")\n",
        "atmos_vars_ds = xr.open_dataset(download_path / \"2023-01-01-atmospheric.nc\", engine=\"netcdf4\")\n",
        "\n",
        "batch = Batch(\n",
        "    surf_vars={\n",
        "        # First select the first two time points: 00:00 and 06:00. Afterwards, `[None]`\n",
        "        # inserts a batch dimension of size one.\n",
        "        \"2t\": torch.from_numpy(surf_vars_ds[\"t2m\"].values[:2][None]),\n",
        "        \"10u\": torch.from_numpy(surf_vars_ds[\"u10\"].values[:2][None]),\n",
        "        \"10v\": torch.from_numpy(surf_vars_ds[\"v10\"].values[:2][None]),\n",
        "        \"msl\": torch.from_numpy(surf_vars_ds[\"msl\"].values[:2][None]),\n",
        "    },\n",
        "    static_vars={\n",
        "        # The static variables are constant, so we just get them for the first time.\n",
        "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
        "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
        "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
        "    },\n",
        "    atmos_vars={\n",
        "        \"t\": torch.from_numpy(atmos_vars_ds[\"t\"].values[:2][None]),\n",
        "        \"u\": torch.from_numpy(atmos_vars_ds[\"u\"].values[:2][None]),\n",
        "        \"v\": torch.from_numpy(atmos_vars_ds[\"v\"].values[:2][None]),\n",
        "        \"q\": torch.from_numpy(atmos_vars_ds[\"q\"].values[:2][None]),\n",
        "        \"z\": torch.from_numpy(atmos_vars_ds[\"z\"].values[:2][None]),\n",
        "    },\n",
        "    metadata=Metadata(\n",
        "        lat=torch.from_numpy(surf_vars_ds.latitude.values),\n",
        "        lon=torch.from_numpy(surf_vars_ds.longitude.values),\n",
        "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
        "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
        "        # one value for every batch element. Select element 1, corresponding to time\n",
        "        # 06:00.\n",
        "        time=(surf_vars_ds.valid_time.values.astype(\"datetime64[s]\").tolist()[1],),\n",
        "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.pressure_level.values),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b6f12fe-1e49-49f0-bf03-bffcea9d1551",
      "metadata": {},
      "source": [
        "## Loading and Running the Model\n",
        "\n",
        "Finally, we are ready to load and run the model and visualise the predictions. We perform a roll-out for two steps, which produces predictions for hours 12:00 and 18:00.\n",
        "\n",
        "The model can be run locally, or [run on Azure AI Foundry](./foundry/intro.md). To run on Foundry, the environment variables `FOUNDRY_ENDPOINT`, `FOUNDRY_TOKEN`, and `BLOB_URL_WITH_SAS` need to be set. If you're unsure on how to set environment variables, see [here](./foundry/intro.md#accessing-environment-variables-in-a-jupyter-notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5084af5f-5a76-4309-b849-fa63cd426fcf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set to `False` to run locally and to `True` to run on Foundry.\n",
        "run_on_foundry = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4824be34-060d-422a-addf-841c2c3609b2",
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m model = model.to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     preds = \u001b[43m[\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m model = model.to(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\aurora\\rollout.py:34\u001b[39m, in \u001b[36mrollout\u001b[39m\u001b[34m(model, batch, steps)\u001b[39m\n\u001b[32m     31\u001b[39m batch = batch.to(p.device)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m pred\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# Add the appropriate history so the model can be run on the prediction.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\aurora\\model\\aurora.py:321\u001b[39m, in \u001b[36mAurora.forward\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    318\u001b[39m transformed_batch = \u001b[38;5;28mself\u001b[39m._pre_encoder_hook(transformed_batch)\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m# The encoder is always just run.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformed_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlead_time\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# In BF16 mode, the backbone is run in pure BF16.\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bf16_mode:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\aurora\\model\\encoder.py:329\u001b[39m, in \u001b[36mPerceiver3DEncoder.forward\u001b[39m\u001b[34m(self, batch, lead_time)\u001b[39m\n\u001b[32m    326\u001b[39m x_atmos = x_atmos + atmos_levels_embed  \u001b[38;5;66;03m# (B, C_A, L, D)\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# Aggregate over pressure levels.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m x_atmos = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate_levels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_atmos\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, C_A, L, D) to (B, C, L, D)\u001b[39;00m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# Concatenate the surface level with the amospheric levels.\u001b[39;00m\n\u001b[32m    332\u001b[39m x = torch.cat((x_surf.unsqueeze(\u001b[32m1\u001b[39m), x_atmos), dim=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\aurora\\model\\encoder.py:193\u001b[39m, in \u001b[36mPerceiver3DEncoder.aggregate_levels\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    190\u001b[39m latents = torch.einsum(\u001b[33m\"\u001b[39m\u001b[33mbcld->blcd\u001b[39m\u001b[33m\"\u001b[39m, latents)\n\u001b[32m    191\u001b[39m latents = latents.flatten(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (B * L, C_A, D)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlevel_agg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B * L, C, D)\u001b[39;00m\n\u001b[32m    194\u001b[39m x = x.unflatten(dim=\u001b[32m0\u001b[39m, sizes=(B, L))  \u001b[38;5;66;03m# (B, L, C, D)\u001b[39;00m\n\u001b[32m    195\u001b[39m x = torch.einsum(\u001b[33m\"\u001b[39m\u001b[33mblcd->bcld\u001b[39m\u001b[33m\"\u001b[39m, x)  \u001b[38;5;66;03m# (B, C, L, D)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\aurora\\model\\perceiver.py:225\u001b[39m, in \u001b[36mPerceiverResampler.forward\u001b[39m\u001b[34m(self, latents, x)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run the module.\u001b[39;00m\n\u001b[32m    214\u001b[39m \n\u001b[32m    215\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m \u001b[33;03m    torch.Tensor: Latent features of shape `(B, L1, D1)`.\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attn, ff, ln1, ln2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# We use post-res-norm like in Swin v2 and most Transformer architectures these days.\u001b[39;00m\n\u001b[32m    224\u001b[39m     \u001b[38;5;66;03m# This empirically works better than the pre-norm used in the original Perceiver.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     attn_out = ln1(\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    226\u001b[39m     \u001b[38;5;66;03m# HuggingFace suggests using non-residual attention in Perceiver might work better when\u001b[39;00m\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# the semantics of the query and the output are different:\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;66;03m#   https://github.com/huggingface/transformers/blob/v4.35.2/src/transformers/models/perceiver/modeling_perceiver.py#L398\u001b[39;00m\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    231\u001b[39m     latents = attn_out + latents \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.residual_latent \u001b[38;5;28;01melse\u001b[39;00m attn_out\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\aurora\\model\\perceiver.py:142\u001b[39m, in \u001b[36mPerceiverAttention.forward\u001b[39m\u001b[34m(self, latents, x)\u001b[39m\n\u001b[32m    139\u001b[39m h = \u001b[38;5;28mself\u001b[39m.num_heads\n\u001b[32m    141\u001b[39m q = \u001b[38;5;28mself\u001b[39m.to_q(latents)  \u001b[38;5;66;03m# (B, L1, D2) to (B, L1, D)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m k, v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_kv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.chunk(\u001b[32m2\u001b[39m, dim=-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (B, L2, D1) to twice (B, L2, D)\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# Apply LN before (!) splitting the heads.\u001b[39;00m\n\u001b[32m    145\u001b[39m k = \u001b[38;5;28mself\u001b[39m.ln_k(k)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
          ]
        }
      ],
      "source": [
        "if not run_on_foundry:\n",
        "    from aurora import Aurora, rollout\n",
        "\n",
        "    model = Aurora(use_lora=False)  # The pretrained version does not use LoRA.\n",
        "    model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\")\n",
        "\n",
        "    model.eval()\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        preds = [pred.to(\"cpu\") for pred in rollout(model, batch, steps=2)]\n",
        "\n",
        "    model = model.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58810cdf-3889-42f0-a9e6-1ce786e3cf6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "if run_on_foundry:\n",
        "    import logging\n",
        "    import os\n",
        "    import warnings\n",
        "\n",
        "    from aurora.foundry import BlobStorageChannel, FoundryClient, submit\n",
        "\n",
        "    # In this demo, we silence all warnings.\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    # But we do want to show what's happening under the hood!\n",
        "    logging.basicConfig(level=logging.WARNING, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "    logging.getLogger(\"aurora\").setLevel(logging.INFO)\n",
        "\n",
        "    foundry_client = FoundryClient(\n",
        "        endpoint=os.environ[\"FOUNDRY_ENDPOINT\"],\n",
        "        token=os.environ[\"FOUNDRY_TOKEN\"],\n",
        "    )\n",
        "    channel = BlobStorageChannel(os.environ[\"BLOB_URL_WITH_SAS\"])\n",
        "\n",
        "    predictions = list(\n",
        "        submit(\n",
        "            batch,\n",
        "            model_name=\"aurora-0.25-pretrained\",\n",
        "            num_steps=2,\n",
        "            foundry_client=foundry_client,\n",
        "            channel=channel,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6e84170-5802-46ad-b4d8-6eb9bf8c98ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize=(12, 6.5))\n",
        "\n",
        "for i in range(ax.shape[0]):\n",
        "    pred = preds[i]\n",
        "\n",
        "    ax[i, 0].imshow(pred.surf_vars[\"2t\"][0, 0].numpy() - 273.15, vmin=-50, vmax=50)\n",
        "    ax[i, 0].set_ylabel(str(pred.metadata.time[0]))\n",
        "    if i == 0:\n",
        "        ax[i, 0].set_title(\"Aurora Prediction\")\n",
        "    ax[i, 0].set_xticks([])\n",
        "    ax[i, 0].set_yticks([])\n",
        "\n",
        "    ax[i, 1].imshow(surf_vars_ds[\"t2m\"][2 + i].values - 273.15, vmin=-50, vmax=50)\n",
        "    if i == 0:\n",
        "        ax[i, 1].set_title(\"ERA5\")\n",
        "    ax[i, 1].set_xticks([])\n",
        "    ax[i, 1].set_yticks([])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61df0128-146b-4721-b734-1143956c9582",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
